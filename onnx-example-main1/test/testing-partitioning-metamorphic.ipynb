{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5453d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932249b9",
   "metadata": {},
   "source": [
    "# Load Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19f03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "def load_data():\n",
    "\n",
    "    data = pd.read_csv('onnx-example-main1/data/synth_data_for_training.csv')\n",
    "\n",
    "    # Let's specify the features and the target\n",
    "    y = data['checked']\n",
    "    X = data.drop(['checked'], axis=1)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Let's split the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05665c",
   "metadata": {},
   "source": [
    "# Loading and Running on Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cdc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for running tests, use this\n",
    "def load_onnx_model(model_path):\n",
    "    sess = rt.InferenceSession(str(model_path))\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ffbc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, X) -> np.ndarray:\n",
    "    input = sess.get_inputs()[0].name\n",
    "    # if you run into issues do X.values.astype(\"float32\")\n",
    "    outputs = sess.run(None, {input: X})\n",
    "    predictions = outputs[0]\n",
    "\n",
    "    if predictions.ndim == 2 and predictions.shape[1] == 2:\n",
    "        return predictions[:,1]\n",
    "    return predictions.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be90b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(sess, X) -> np.ndarray:\n",
    "    labels = predict(sess, X)\n",
    "    return (labels >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b0113",
   "metadata": {},
   "source": [
    "# Partitioning Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "388df034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age, gender, and language proxies\n",
    "\n",
    "# gender\n",
    "\n",
    "def test_gender_accuracy_similar(model_path):\n",
    "    _ , X_test, _ , y_test = load_data()\n",
    "    sess = load_onnx_model(model_path)\n",
    "\n",
    "    GENDER_COL = \"persoon_geslacht_vrouw\"\n",
    "\n",
    "    assert GENDER_COL in X_test.columns, f\"{GENDER_COL} not in dataset\"\n",
    "\n",
    "    filter_empty = X_test[GENDER_COL].notna()\n",
    "    X_test = X_test[filter_empty]\n",
    "    y_test = y_test[filter_empty]\n",
    "\n",
    "    women = X_test[GENDER_COL] == 1\n",
    "    other = X_test[GENDER_COL] == 0\n",
    "\n",
    "    # remove if not needed\n",
    "    assert women.sum() > 40, \"Not enough women!\"\n",
    "    assert other.sum() > 40, \"Not enough others!\"\n",
    "\n",
    "    y_pred = predict_labels(sess, X_test)\n",
    "\n",
    "    women_accuracy = accuracy_score(y_test[women], y_pred[women])\n",
    "    other_accuracy = accuracy_score(y_test[other], y_pred[other])\n",
    "\n",
    "    difference = abs(women_accuracy - other_accuracy)\n",
    "    print(f\"[Partition gender] women_accuracy={women_accuracy:.3f}, other_accuracy={other_accuracy:.3f}, diff={difference:.3f}\")\n",
    "\n",
    "    tolerance = 0.18\n",
    "    assert difference<=tolerance, (f\"{difference:.3f} > {tolerance:.3f}. Difference is too large.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335408bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age, gender, and language proxies\n",
    "\n",
    "# gender\n",
    "\n",
    "def test_gender_rate(model_path):\n",
    "    _ , X_test, _ , _ = load_data()\n",
    "    sess = load_onnx_model(model_path)\n",
    "\n",
    "    GENDER_COL = \"persoon_geslacht_vrouw\"\n",
    "\n",
    "    assert GENDER_COL in X_test.columns, f\"{GENDER_COL} not in dataset\"\n",
    "\n",
    "    filter_empty = X_test[GENDER_COL].notna()\n",
    "    X_test = X_test[filter_empty]\n",
    "\n",
    "    women = X_test[GENDER_COL] == 1\n",
    "    other = X_test[GENDER_COL] == 0\n",
    "\n",
    "    # remove if not needed\n",
    "    assert women.sum() > 40, \"Not enough women!\"\n",
    "    assert other.sum() > 40, \"Not enough others!\"\n",
    "\n",
    "    y_pred = predict_labels(sess, X_test)\n",
    "\n",
    "    women_rate = y_pred[women].mean()\n",
    "    other_rate = y_pred[other].mean()\n",
    "\n",
    "    difference = abs(women_rate - other_rate)\n",
    "    print(f\"[Partition gender] women_rate={women_rate:.3f}, other_rate={other_rate:.3f}, diff={difference:.3f}\")\n",
    "\n",
    "    tolerance = 0.22\n",
    "    assert difference<=tolerance, (f\"{difference:.3f} > {tolerance:.3f}. Difference is too large.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c407e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age, gender, and language proxies\n",
    "\n",
    "# age\n",
    "\n",
    "def test_age_accuracy_similar(model_path):\n",
    "    _ , X_test, _ , y_test = load_data()\n",
    "    sess = load_onnx_model(model_path)\n",
    "\n",
    "    AGE_COL = \"persoon_leeftijd_bij_onderzoek\"\n",
    "\n",
    "    assert AGE_COL in X_test.columns, f\"{AGE_COL} not in dataset\"\n",
    "\n",
    "    filter_empty = X_test[AGE_COL].notna()\n",
    "    X_test = X_test[filter_empty]\n",
    "    y_test = y_test[filter_empty]\n",
    "\n",
    "    age = X_test[AGE_COL]\n",
    "\n",
    "    age_groups = {\n",
    "        \"young\": age < 30,\n",
    "        \"middle\": (age >= 30) & (age < 60),\n",
    "        \"senior\": age >= 60,\n",
    "    }\n",
    "\n",
    "\n",
    "    y_pred = predict_labels(sess, X_test)\n",
    "\n",
    "    accuracies = {}\n",
    "    for name, filtered in age_groups.items():\n",
    "        if filtered.sum() < 30:\n",
    "            continue\n",
    "        accuracy = accuracy_score(y_test[filtered], y_pred[filtered])\n",
    "        accuracies[name] = accuracy\n",
    "        print(f\"[Partition age] {name:>6}: accuracy={accuracy:.3f}, number={filtered.sum()}\")\n",
    "\n",
    "    accuracy_list = list(accuracies.values())\n",
    "    max_difference = max(accuracy_list) - min(accuracy_list)\n",
    "\n",
    "\n",
    "    tolerance = 0.20\n",
    "    assert max_difference<=tolerance, (f\"{max_difference:.3f} > {tolerance:.3f}. Difference is too large.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc1ffc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGUAGE_COLS = [\n",
    "#     \"persoonlijke_eigenschappen_nl_lezen3\",\n",
    "#     \"persoonlijke_eigenschappen_nl_lezen4\",\n",
    "#     \"persoonlijke_eigenschappen_nl_schrijven0\",\n",
    "#     \"persoonlijke_eigenschappen_nl_schrijven1\",\n",
    "#     \"persoonlijke_eigenschappen_nl_schrijven2\",\n",
    "#     \"persoonlijke_eigenschappen_nl_schrijven3\",\n",
    "#     \"persoonlijke_eigenschappen_nl_spreken1\",\n",
    "#     \"persoonlijke_eigenschappen_nl_spreken2\",\n",
    "#     \"persoonlijke_eigenschappen_nl_spreken3\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7978c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age, gender, and language proxies\n",
    "\n",
    "# language\n",
    "\n",
    "def test_language_accuracy_similar(model_path):\n",
    "    _ , X_test, _ , y_test = load_data()\n",
    "    sess = load_onnx_model(model_path)\n",
    "\n",
    "    LANGUAGE_COL = \"persoonlijke_eigenschappen_spreektaal_anders\"\n",
    "\n",
    "    assert LANGUAGE_COL in X_test.columns, f\"{LANGUAGE_COL} not in dataset\"\n",
    "\n",
    "\n",
    "    filter_empty = X_test[LANGUAGE_COL].notna()\n",
    "    X_test = X_test[filter_empty]\n",
    "    y_test = y_test[filter_empty]\n",
    "\n",
    "    dutch = X_test[LANGUAGE_COL] == 0\n",
    "    non_dutch = X_test[LANGUAGE_COL] == 1\n",
    "\n",
    "    # remove if not needed\n",
    "    assert dutch.sum() > 40, \"Not enough dutch speaking people!\"\n",
    "    assert non_dutch.sum() > 40, \"Not enough non_dutch speaking people!\"\n",
    "\n",
    "    y_pred = predict_labels(sess, X_test)\n",
    "\n",
    "    dutch_accuracy = accuracy_score(y_test[dutch], y_pred[dutch])\n",
    "    non_dutch_accuracy = accuracy_score(y_test[non_dutch], y_pred[non_dutch])\n",
    "\n",
    "    difference = abs(dutch_accuracy - non_dutch_accuracy)\n",
    "    print(f\"[Partition language] dutch_accuracy={dutch_accuracy:.3f}, non_dutch_accuracy={non_dutch_accuracy:.3f}, diff={difference:.3f}\")\n",
    "\n",
    "    tolerance = 0.20\n",
    "    assert difference<=tolerance, (f\"{difference:.3f} > {tolerance:.3f}. Difference is too large.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b0f368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age, gender, and language proxies\n",
    "\n",
    "# language\n",
    "\n",
    "def test_language_rate(model_path):\n",
    "    _ , X_test, _ , _ = load_data()\n",
    "    sess = load_onnx_model(model_path)\n",
    "\n",
    "    LANGUAGE_COL = \"persoonlijke_eigenschappen_spreektaal_anders\"\n",
    "\n",
    "    assert LANGUAGE_COL in X_test.columns, f\"{LANGUAGE_COL} not in dataset\"\n",
    "\n",
    "    filter_empty = X_test[LANGUAGE_COL].notna()\n",
    "    X_test = X_test[filter_empty]\n",
    "\n",
    "    dutch = X_test[LANGUAGE_COL] == 0\n",
    "    non_dutch = X_test[LANGUAGE_COL] == 1\n",
    "\n",
    "    # remove if not needed\n",
    "    assert dutch.sum() > 40, \"Not enough dutch speaking people!\"\n",
    "    assert non_dutch.sum() > 40, \"Not enough non-dutch speaking people!\"\n",
    "\n",
    "    y_pred = predict_labels(sess, X_test)\n",
    "\n",
    "    dutch_rate = y_pred[dutch].mean()\n",
    "    non_dutch_rate = y_pred[non_dutch].mean()\n",
    "\n",
    "    difference = abs(dutch_rate - non_dutch)\n",
    "    print(f\"[Partition language] dutch_rate={dutch_rate:.3f}, non_dutch_rate={non_dutch_rate:.3f}, diff={difference:.3f}\")\n",
    "\n",
    "    tolerance = 0.20\n",
    "    assert difference<=tolerance, (f\"{difference:.3f} > {tolerance:.3f}. Difference is too large.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16047c",
   "metadata": {},
   "source": [
    "# Metamorphic Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddcf1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Metamorphic Data Augmentation: Gender Flipping\n",
    "# ============================================================\n",
    "\n",
    "# Gender transformation map (same as above)\n",
    "gender_flip_map = {\n",
    "    1: 0,\n",
    "    0: 1\n",
    "}\n",
    "\n",
    "def flip_gender_all(val):\n",
    "    \"\"\"Flip gender if possible, otherwise return original.\"\"\"\n",
    "    return gender_flip_map.get(val, val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e54d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flip_gender_train():\n",
    "\n",
    "#     # --------------------------\n",
    "#     # Create flipped training set\n",
    "#     # --------------------------\n",
    "#     X_train_flipped = X_train.copy()\n",
    "#     X_train_flipped[\"Attribute9\"] = X_train_flipped[\"Attribute9\"].apply(flip_gender_all)\n",
    "\n",
    "#     # y_train does not change\n",
    "#     y_train_flipped = y_train.copy()\n",
    "\n",
    "#     # --------------------------\n",
    "#     # Augment the training data\n",
    "#     # --------------------------\n",
    "#     X_train_aug = pd.concat([X_train, X_train_flipped], ignore_index=True)\n",
    "#     y_train_aug = pd.concat([y_train, y_train_flipped], ignore_index=True)\n",
    "\n",
    "#     print(\"Original training size:\", len(X_train))\n",
    "#     print(\"Augmented training size:\", len(X_train_aug))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fec164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_aug = DecisionTreeClassifier()\n",
    "# clf_aug.fit(X_train_aug, y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71d03d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flig_gender_test(model_path):\n",
    "    _ , X_test, _ , y_test = load_data()\n",
    "    sess = load_onnx_model(model_path)\n",
    "\n",
    "    # Create a copy of test set\n",
    "    X_test_flipped = X_test.copy()\n",
    "\n",
    "    X_test_flipped['persoon_geslacht_vrouw'] = X_test_flipped['persoon_geslacht_vrouw'].apply(flip_gender_all)\n",
    "\n",
    "    # Predict with flipped gender\n",
    "    y_pred_original = predict_labels(sess, X_test)\n",
    "    y_pred_flipped = predict_labels(sess, X_test_flipped)\n",
    "\n",
    "    # Compare\n",
    "    print(\"Accuracy after gender flip:\", accuracy_score(y_test, y_pred_flipped))\n",
    "    print(\"Changed predictions:\", np.sum(y_pred_original != y_pred_flipped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08cc6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # Metamorphic Data Augmentation: Gender Flipping\n",
    "# # ============================================================\n",
    "\n",
    "# # Gender transformation map (same as above)\n",
    "# gender_flip_map = {\n",
    "#     1: 2,\n",
    "#     2: 1,\n",
    "#     3: 5,\n",
    "#     5: 3\n",
    "# }\n",
    "\n",
    "# def flip_gender_all(val):\n",
    "#     \"\"\"Flip gender if possible, otherwise return original.\"\"\"\n",
    "#     return gender_flip_map.get(val, val)\n",
    "\n",
    "\n",
    "# # --------------------------\n",
    "# # Create flipped training set\n",
    "# # --------------------------\n",
    "# X_train_flipped = X_train.copy()\n",
    "# X_train_flipped[\"Attribute9\"] = X_train_flipped[\"Attribute9\"].apply(flip_gender_all)\n",
    "\n",
    "# # y_train does not change\n",
    "# y_train_flipped = y_train.copy()\n",
    "\n",
    "# # --------------------------\n",
    "# # Augment the training data\n",
    "# # --------------------------\n",
    "# X_train_aug = pd.concat([X_train, X_train_flipped], ignore_index=True)\n",
    "# y_train_aug = pd.concat([y_train, y_train_flipped], ignore_index=True)\n",
    "\n",
    "# print(\"Original training size:\", len(X_train))\n",
    "# print(\"Augmented training size:\", len(X_train_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffc32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_aug = DecisionTreeClassifier()\n",
    "# clf_aug.fit(X_train_aug, y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f627c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a copy of test set\n",
    "# X_test_flipped = X_test.copy()\n",
    "\n",
    "# # Apply to Attribute9 (column 8)\n",
    "# X_test_flipped['Attribute9'] = X_test_flipped['Attribute9'].apply(flip_gender_all)\n",
    "\n",
    "# # Predict with flipped gender\n",
    "# y_pred_original = clf_aug.predict(X_test)\n",
    "# y_pred_flipped = clf_aug.predict(X_test_flipped)\n",
    "\n",
    "# # Compare\n",
    "# print(\"Accuracy after gender flip:\", metrics.accuracy_score(y_test, y_pred_flipped))\n",
    "# print(\"Changed predictions:\", np.sum(y_pred_original != y_pred_flipped))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
